{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fda1b109-6e0c-4678-96fa-70e020046a16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Window 함수: ROWS BETWEEN AND 이해 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63a00608-c929-4db6-bba8-992c950111b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "BX91cDdZj3AK"
   },
   "outputs": [],
   "source": [
    "rows_test = [\n",
    "    { 'value': 1, 'name': 'Luka', 'ts': '2025-04-01' },\n",
    "    { 'value': 2, 'name': 'Luka', 'ts': '2025-04-03'},\n",
    "    { 'value': 3, 'name': 'Dirk', 'ts': '2025-04-01'},\n",
    "    { 'value': 4, 'name': 'Dirk', 'ts': '2025-04-30' },\n",
    "    { 'value': 5, 'name': 'Luka', 'ts': '2025-04-30' },\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b70f3f19-9c47-458a-b59c-0a0881a56bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XRkbATLkfkt",
    "outputId": "01a6741e-3ee6-4e54-bb98-33491b1f87d6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: string (nullable = true)\n |-- ts: string (nullable = true)\n |-- value: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947ef236-3805-4455-9cb7-82e0d752b4ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMvZ11_71j9F",
    "outputId": "735f1c17-619b-4d2f-de41-0f569f6eccb3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n|name|        ts|value|\n+----+----------+-----+\n|Luka|2025-04-01|    1|\n|Luka|2025-04-03|    2|\n|Dirk|2025-04-01|    3|\n|Dirk|2025-04-30|    4|\n|Luka|2025-04-30|    5|\n+----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05454698-9e8e-453a-a13f-88b78f0528fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "S0ZGpnfhk1kP"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"rows_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1986911-742b-4c82-a6e4-59909db87591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 앞에서 봤던 rolling sum 5개를 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fedc5a7-d63a-4811-b35e-e85874e7bb69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OGdFV7MlCZf",
    "outputId": "baaa208d-7c5a-4005-d2f2-946bb6654fa6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n|value|rolling_sum|\n+-----+-----------+\n|    1|          6|\n|    2|         10|\n|    3|         15|\n|    4|         14|\n|    5|         12|\n+-----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    value,\n",
    "    SUM(value) OVER (\n",
    "        ORDER BY value \n",
    "        ROWS BETWEEN 2 PRECEDING and 2 FOLLOWING\n",
    "    ) AS rolling_sum\n",
    "  FROM rows_test\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28cea620-ff0e-4fd1-aa1d-24323d3c43e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 이번에는 앞에는 모두 더하고 뒤는 2개만 더하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb55e8e-0a39-4d48-8540-f8961032a0d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Ffkge4xmrMr",
    "outputId": "13360eff-d1dd-4b02-9ec8-6ac0bb51536f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n|value|rolling_sum|\n+-----+-----------+\n|    1|          6|\n|    2|         10|\n|    3|         15|\n|    4|         15|\n|    5|         15|\n+-----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    value,\n",
    "    SUM(value) OVER (\n",
    "        ORDER BY value \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND 2 FOLLOWING\n",
    "    ) AS rolling_sum\n",
    "  FROM rows_test\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "680f219f-552c-4444-8ca6-f2f25995e9ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 같은 name을 갖는 레코드들중에서 시간순으로 봤을 때 (ts) 처음 value(initial_value)와 마지막 value(last_value)를 알고 싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c75c66db-2322-40e4-aec7-e7cc700f2a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+-------------+----------+\n|name|        ts|value|initial_value|last_value|\n+----+----------+-----+-------------+----------+\n|Dirk|2025-04-01|    3|            3|         4|\n|Dirk|2025-04-30|    4|            3|         4|\n|Luka|2025-04-01|    1|            1|         5|\n|Luka|2025-04-03|    2|            1|         5|\n|Luka|2025-04-30|    5|            1|         5|\n+----+----------+-----+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    *,\n",
    "    FIRST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS initial_value,\n",
    "    LAST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS last_value    \n",
    "  FROM rows_test\n",
    "  ORDER BY name\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8acf133d-6fd6-4aff-8569-a20c893683da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+\n|name|initial_value|last_value|\n+----+-------------+----------+\n|Dirk|            3|         4|\n|Dirk|            3|         4|\n|Luka|            1|         5|\n|Luka|            1|         5|\n|Luka|            1|         5|\n+----+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    name,\n",
    "    FIRST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS initial_value,\n",
    "    LAST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS last_value    \n",
    "  FROM rows_test\n",
    "  ORDER BY name\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d07c50-b3bb-47b0-aad6-c5071bf85424",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+\n|name|initial_value|last_value|\n+----+-------------+----------+\n|Dirk|            3|         4|\n|Luka|            1|         5|\n+----+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    DISTINCT\n",
    "    name,\n",
    "    FIRST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS initial_value,\n",
    "    LAST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS last_value    \n",
    "  FROM rows_test\n",
    "  ORDER BY name\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d587b10-e950-45fd-8446-a95eda42c71b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 같은 name을 갖는 레코드들에 시간순으로 일련번호를 붙이고 싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c2ef96-123d-458f-9956-7280de56b2a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+-------------+----------+---+\n|name|        ts|value|initial_value|last_value|seq|\n+----+----------+-----+-------------+----------+---+\n|Dirk|2025-04-01|    3|            3|         4|  1|\n|Dirk|2025-04-30|    4|            3|         4|  2|\n|Luka|2025-04-01|    1|            1|         5|  1|\n|Luka|2025-04-03|    2|            1|         5|  2|\n|Luka|2025-04-30|    5|            1|         5|  3|\n+----+----------+-----+-------------+----------+---+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT \n",
    "    *,\n",
    "    FIRST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        rows between unbounded preceding and unbounded following\n",
    "    ) AS initial_value,\n",
    "    LAST_VALUE(value) OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts \n",
    "        rows between unbounded preceding and unbounded following\n",
    "    ) AS last_value,\n",
    "    ROW_NUMBER() OVER (\n",
    "        PARTITION BY name\n",
    "        ORDER BY ts\n",
    "    ) AS seq   \n",
    "  FROM rows_test\n",
    "  ORDER BY name\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1be0225-7605-440c-8c19-a4faa266de8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 사용자별로 처음 채널과 마지막 채널을 알아내기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3ed1284-f2b1-4e0f-b3be-f346c3ba3913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 데이터셋 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8193ce2-af28-4e67-812b-85311c0188dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EEaNuN3xKNXm"
   },
   "outputs": [],
   "source": [
    "df_user_session_channel = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"s3a://s3-geospatial/readonly/user_session_channel.csv\")\n",
    "\n",
    "df_session_timestamp = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"s3a://s3-geospatial/readonly/session_timestamp.csv\")\n",
    "\n",
    "df_session_transaction = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"s3a://s3-geospatial/readonly/session_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e1cc8ad-6609-439b-8355-388ca9124200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "AjcT5LWi7_B5"
   },
   "outputs": [],
   "source": [
    "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")\n",
    "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")\n",
    "df_session_transaction.createOrReplaceTempView(\"session_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93ab12fe-00c2-4548-bb45-1327e8ececce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3UxHdoLC5Bt",
    "outputId": "85e24cdb-fee6-4889-9056-4347a2776d09"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------+\n|userid|           sessionid| channel|\n+------+--------------------+--------+\n|   184|c41dd99a69df04044...|   Naver|\n|    80|fdc0eb412a84fa549...| Organic|\n|   251|0a54b19a13b6712dc...|Facebook|\n|   264|a914ecef9c12ffdb9...|  Google|\n|   744|05ae14d7ae387b933...|Facebook|\n+------+--------------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_user_session_channel.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac7a7357-8cb6-40ed-8e4f-7ba4134f7bcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9lIcukADIgk",
    "outputId": "de7a4728-32f5-412a-a053-4dd702642b31"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n|           sessionid|                  ts|\n+--------------------+--------------------+\n|7cdace91c487558e2...|2019-05-01 00:13:...|\n|94f192dee566b018e...|2019-05-01 00:49:...|\n|7ed2d3454c5eea711...|2019-05-01 10:18:...|\n|f1daf122cde863010...|2019-05-01 13:10:...|\n|fd0efcca272f704a7...|2019-05-01 13:45:...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_session_timestamp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e18d8d1-fb0e-4d4e-8e32-128075e12f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwiwGeXRDNk2",
    "outputId": "af76c473-4949-4f1f-98fe-412b5f35177a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n|           sessionid|refunded|amount|\n+--------------------+--------+------+\n|00029153d12ae1c9a...|   false|    85|\n|008909bd27b680698...|   false|    13|\n|0107acb41ef20db22...|   false|    16|\n|018544a2c48077d2c...|   false|    39|\n|020c38173caff0203...|   false|    61|\n+--------------------+--------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_session_transaction.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "375b61b0-39c3-4017-9a26-8b6a9cafafa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mpjU9yXVJAph"
   },
   "source": [
    "### ROW_NUMBER를 사용해서 사용자별 처음 채널과 마지막 채널 알아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06bdd3b7-e5a6-4d07-90ef-0996c5c92d11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "F8DVGlKRQkrD"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+------------+\n|userid|first_channel|last_channel|\n+------+-------------+------------+\n|    27|      Youtube|   Instagram|\n|    29|        Naver|       Naver|\n|    33|       Google|     Youtube|\n|    34|      Youtube|       Naver|\n|    36|        Naver|     Youtube|\n|    40|      Youtube|      Google|\n|    41|     Facebook|     Youtube|\n|    44|        Naver|   Instagram|\n|    45|      Youtube|   Instagram|\n|    59|    Instagram|   Instagram|\n|    64|      Youtube|     Youtube|\n|    65|      Youtube|     Organic|\n|    68|      Youtube|     Organic|\n|    69|     Facebook|   Instagram|\n|    80|      Organic|       Naver|\n|    84|       Google|     Youtube|\n|    87|      Youtube|      Google|\n|    97|      Organic|     Organic|\n|   112|     Facebook|     Youtube|\n|   113|      Organic|     Organic|\n+------+-------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH RECORD AS (\n",
    "  SELECT /*사용자의 유입에 따른, 채널 순서 매기는 쿼리*/\n",
    "      userid,\n",
    "      channel, \n",
    "      ROW_NUMBER() OVER (PARTITION BY userid ORDER BY ts ASC) AS seq_first,\n",
    "      ROW_NUMBER() OVER (PARTITION BY userid ORDER BY ts DESC) AS seq_last\n",
    "  FROM user_session_channel u\n",
    "  LEFT JOIN session_timestamp t\n",
    "    ON u.sessionid = t.sessionid\n",
    ")\n",
    "SELECT /*유저의 첫번째 유입채널, 마지막 유입 채널 구하기*/\n",
    "      f.userid,\n",
    "      f.channel first_channel,\n",
    "      l.channel last_channel\n",
    "FROM RECORD f\n",
    "INNER JOIN RECORD l ON f.userid = l.userid\n",
    "WHERE f.seq_first = 1 and l.seq_last = 1\n",
    "ORDER BY userid\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94e9108d-f73c-43e9-a5f6-1437fa729a8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### FIRST_VALUE와 LAST_VALUE를 사용해서 사용자별 처음 채널과 마지막 채널 알아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f06dd03-e6c0-4829-81bb-4812cc22d072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "rvBR0KhAc5J1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+------------+\n|userid|First_Channel|Last_Channel|\n+------+-------------+------------+\n|    27|      Youtube|   Instagram|\n|    29|        Naver|       Naver|\n|    33|       Google|     Youtube|\n|    34|      Youtube|       Naver|\n|    36|        Naver|     Youtube|\n|    40|      Youtube|      Google|\n|    41|     Facebook|     Youtube|\n|    44|        Naver|   Instagram|\n|    45|      Youtube|   Instagram|\n|    59|    Instagram|   Instagram|\n|    64|      Youtube|     Youtube|\n|    65|      Youtube|     Organic|\n|    68|      Youtube|     Organic|\n|    69|     Facebook|   Instagram|\n|    80|      Organic|       Naver|\n|    84|       Google|     Youtube|\n|    87|      Youtube|      Google|\n|    97|      Organic|     Organic|\n|   112|     Facebook|     Youtube|\n|   113|      Organic|     Organic|\n+------+-------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT A.userid,\n",
    "    FIRST_VALUE(A.channel) over(partition by A.userid order by B.ts\n",
    "rows between unbounded preceding and unbounded following) AS First_Channel,\n",
    "    LAST_VALUE(A.channel) over(partition by A.userid order by B.ts\n",
    "rows between unbounded preceding and unbounded following) AS Last_Channel\n",
    "FROM user_session_channel A\n",
    "LEFT JOIN session_timestamp B\n",
    "ON A.sessionid = B.sessionid\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3107978579352048,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "사용자별로 처음 채널과 마지막 채널 알아내기",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}